import asyncio
from pathlib import Path
from typing import Optional
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.parser.markdown_parser import MarkdownDocumentParser, MarkdownChunk
from src.summarizer.llm_client import LLMManager
from src.summarizer.summary_generator import SummaryGenerator, SummaryResult, SummaryPostProcessor
from src.output.markdown_formatter_v2 import MarkdownFormatterV2
from src.utils.config import load_config, Config
from tqdm import tqdm


class MinerUSummarizerV2:
    """MinerUå†…å®¹æ€»ç»“å™¨ V2ç‰ˆæœ¬ - åŸºäºLangchain Markdownåˆ†å‰²"""
    
    def __init__(self, config: Config):
        self.config = config
        
    async def summarize(
        self, 
        input_dir: Path, 
        output_path: Path,
        compression_level: int = 50
    ) -> None:
        """æ‰§è¡Œæ€»ç»“ä»»åŠ¡"""
        print(f"ğŸš€ å¼€å§‹å¤„ç†MinerUæ•°æ® (V2ç‰ˆæœ¬): {input_dir}")
        print(f"ğŸ“Š å‹ç¼©çº§åˆ«: {compression_level}%")
        print(f"ğŸ“„ è¾“å‡ºè·¯å¾„: {output_path}")
        
        # 1. è§£æMarkdownæ–‡æ¡£
        print("\næ­¥éª¤1: è§£æMarkdownæ–‡æ¡£...")
        full_md_path = input_dir / "full.md"
        if not full_md_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°full.mdæ–‡ä»¶: {full_md_path}")
        
        parser = MarkdownDocumentParser(
            chunk_size=self.config.processing.chunk_size,
            chunk_overlap=self.config.processing.overlap
        )
        
        markdown_chunks = parser.parse_markdown_file(full_md_path)
        print(f"è§£æå®Œæˆ: {len(markdown_chunks)} ä¸ªæ–‡æ¡£å—")
        
        # æ˜¾ç¤ºæ–‡æ¡£ç»“æ„
        if self.config.processing.preserve_structure:
            parser.print_hierarchy(markdown_chunks)
        
        # 2. ç”Ÿæˆæ€»ç»“
        print(f"\næ­¥éª¤2: ç”Ÿæˆæ€»ç»“...")
        summaries = await self._generate_summaries(markdown_chunks, compression_level)
        print(f"æ€»ç»“ç”Ÿæˆå®Œæˆ: {len(summaries)} ä¸ªæ€»ç»“å—")
        
        # 3. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        overall_stats = SummaryPostProcessor.calculate_overall_stats(summaries)
        print(f"æ€»ä½“ç»Ÿè®¡: {overall_stats}")
        
        # 4. æ ¼å¼åŒ–è¾“å‡º
        print(f"\næ­¥éª¤3: æ ¼å¼åŒ–è¾“å‡º...")
        formatter = MarkdownFormatterV2(self.config.output)
        
        # ä»ç¬¬ä¸€ä¸ªå—æå–æ ‡é¢˜
        original_title = self._extract_title(markdown_chunks)
        
        formatted_content = formatter.format_summaries(
            summaries=summaries,
            original_title=original_title,
            compression_level=compression_level,
            stats=overall_stats
        )
        
        # 5. ä¿å­˜æ–‡ä»¶
        formatter.save_to_file(formatted_content, output_path)
        
        print(f"\nâœ… æ€»ç»“å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"ğŸ“Š åŸå§‹å†…å®¹: {overall_stats.get('total_original_tokens', 0):,} tokens")
        print(f"ğŸ“ æ€»ç»“å†…å®¹: {overall_stats.get('total_summary_tokens', 0):,} tokens") 
        print(f"ğŸ¯ å‹ç¼©æ¯”: {overall_stats.get('overall_compression_ratio', 0):.2%}")
    
    async def _generate_summaries(
        self, 
        markdown_chunks: list[MarkdownChunk], 
        compression_level: int
    ) -> list[SummaryResult]:
        """ç”Ÿæˆæ€»ç»“"""
        
        if compression_level not in self.config.compression_levels:
            raise ValueError(f"ä¸æ”¯æŒçš„å‹ç¼©çº§åˆ«: {compression_level}")
        
        compression_config = self.config.compression_levels[compression_level]
        
        print(f"å¼€å§‹ç”Ÿæˆæ€»ç»“ (å‹ç¼©çº§åˆ«: {compression_level}%)")
        print(f"æ€»å…±éœ€è¦å¤„ç† {len(markdown_chunks)} ä¸ªæ–‡æ¡£å—")
        
        # ç”Ÿæˆæç¤ºè¯
        prompts = []
        for chunk in markdown_chunks:
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = ""
            if chunk.headers:
                header_path = " > ".join([h[1] for h in chunk.headers])
                context_info = f"\n\nç« èŠ‚è·¯å¾„: {header_path}"
            
            # æ„å»ºå®Œæ•´æç¤ºè¯
            full_prompt = f"""{compression_config.prompt_template}

{context_info}

ç‰¹åˆ«è¦æ±‚:
- ä¿æŒå­¦æœ¯å†™ä½œçš„ä¸¥è°¨æ€§å’Œä¸“ä¸šæ€§
- ä½¿ç”¨ä¸­æ–‡å­¦æœ¯å†™ä½œçš„è§„èŒƒè¡¨è¾¾æ–¹å¼
- å¦‚æœå†…å®¹å¾ˆçŸ­æˆ–åªæ˜¯ç›®å½•ï¼Œè¯·ç®€æ´åœ°ç”¨ä¸­æ–‡æè¿°å…¶ä½œç”¨

åŸæ–‡å†…å®¹:
{chunk.content}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š"""
            
            prompts.append(full_prompt)
        
        # æ‰¹é‡è°ƒç”¨LLM
        summaries = []
        async with LLMManager(
            self.config.llm, 
            max_concurrent=self.config.processing.max_concurrent
        ) as llm_manager:
            
            with tqdm(total=len(prompts), desc="ç”Ÿæˆæ€»ç»“") as pbar:
                batch_size = self.config.processing.max_concurrent
                
                for i in range(0, len(prompts), batch_size):
                    batch_prompts = prompts[i:i+batch_size]
                    batch_chunks = markdown_chunks[i:i+batch_size]
                    
                    batch_results = await llm_manager.batch_generate(batch_prompts)
                    
                    # åˆ›å»ºç»“æœå¯¹è±¡
                    for chunk, summary in zip(batch_chunks, batch_results):
                        # ç¡®å®šç« èŠ‚æ ‡é¢˜å’Œçº§åˆ«
                        section_title = chunk.headers[0][1] if chunk.headers else "Unknown"
                        section_level = chunk.headers[0][0] if chunk.headers else 1
                        
                        result = SummaryResult(
                            chunk_id=chunk.id,
                            original_content=chunk.content,
                            summary=summary,
                            section_title=section_title,
                            section_level=section_level,
                            token_count=len(summary.split()),
                            compression_ratio=self._calculate_compression_ratio(
                                chunk.content, summary
                            ),
                            metadata={
                                'compression_level': compression_level,
                                'strategy': compression_config.strategy,
                                'original_token_count': chunk.token_count,
                                'headers': chunk.headers,
                                'langchain_metadata': chunk.metadata
                            }
                        )
                        summaries.append(result)
                    
                    pbar.update(len(batch_prompts))
        
        return summaries
    
    def _calculate_compression_ratio(self, original: str, summary: str) -> float:
        """è®¡ç®—å‹ç¼©æ¯”ä¾‹"""
        original_length = len(original)
        summary_length = len(summary)
        
        if original_length == 0:
            return 0.0
        
        return summary_length / original_length
    
    def _extract_title(self, chunks: list[MarkdownChunk]) -> str:
        """ä»æ–‡æ¡£å—ä¸­æå–æ ‡é¢˜"""
        for chunk in chunks:
            if chunk.headers and chunk.headers[0][0] == 1:
                return chunk.headers[0][1]
        return "å­¦æœ¯è®ºæ–‡"


async def main():
    """ä¸»å‡½æ•°"""
    # ç®€å•çš„å‘½ä»¤è¡Œå‚æ•°è§£æ
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python -m src.main_v2 <è¾“å…¥ç›®å½•> <è¾“å‡ºæ–‡ä»¶> [å‹ç¼©çº§åˆ«] [é…ç½®æ–‡ä»¶]")
        print("ç¤ºä¾‹: python -m src.main_v2 ./GFM_SURVEY ./summary_v2.md 30")
        sys.exit(1)
    
    input_dir = Path(sys.argv[1])
    output_path = Path(sys.argv[2])
    compression_level = int(sys.argv[3]) if len(sys.argv) > 3 else 50
    config_path = sys.argv[4] if len(sys.argv) > 4 else None
    
    # éªŒè¯è¾“å…¥ç›®å½•
    if not input_dir.exists():
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        sys.exit(1)
    
    full_md_path = input_dir / "full.md"
    if not full_md_path.exists():
        print(f"é”™è¯¯: æœªæ‰¾åˆ°full.mdæ–‡ä»¶: {full_md_path}")
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    try:
        config = load_config(config_path)
        print(f"âœ… é…ç½®åŠ è½½å®Œæˆ: LLMæä¾›å•†={config.llm.provider}, æ¨¡å‹={config.llm.model}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: é…ç½®åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)
    
    # éªŒè¯APIå¯†é’¥
    if not config.llm.api_key:
        print("âŒ é”™è¯¯: æœªé…ç½®APIå¯†é’¥ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶")
        print("OpenAI: è®¾ç½® OPENAI_API_KEY")
        print("Anthropic: è®¾ç½® ANTHROPIC_API_KEY")
        sys.exit(1)
    
    # åˆ›å»ºæ€»ç»“å™¨å¹¶æ‰§è¡Œ
    try:
        summarizer = MinerUSummarizerV2(config)
        await summarizer.summarize(input_dir, output_path, compression_level)
    except Exception as e:
        print(f"âŒ é”™è¯¯: å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())