import asyncio
from pathlib import Path
from typing import Optional, List
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.parser.chapter_parser import ChapterBasedParser, ChapterChunk
from src.summarizer.claude_cli_client import ClaudeCLIManager, ClaudeCLIConfig
from src.summarizer.summary_generator import SummaryResult, SummaryPostProcessor
from src.output.markdown_formatter_v2 import MarkdownFormatterV2
from src.utils.config import load_config, Config
from src.utils.checkpoint import CheckpointManager, CheckpointState, print_checkpoints_table
from tqdm import tqdm
from datetime import datetime


class MinerUSummarizerV6:
    """MinerUå†…å®¹æ€»ç»“å™¨ V6ç‰ˆæœ¬ - å¸¦æ£€æŸ¥ç‚¹æ¢å¤åŠŸèƒ½çš„Claude CLIç‰ˆæœ¬"""
    
    def __init__(self, config: Config, checkpoint_dir: Path = None):
        self.config = config
        self.checkpoint_manager = CheckpointManager(checkpoint_dir)
        
    async def summarize(
        self, 
        input_dir: Path, 
        output_path: Path,
        compression_level: int = 50,
        max_tokens_per_chapter: int = 8000,
        enable_polish: bool = True,
        claude_project: Optional[str] = None,
        claude_model: Optional[str] = None,
        resume_session: Optional[str] = None
    ) -> None:
        """æ‰§è¡Œæ€»ç»“ä»»åŠ¡"""
        
        if resume_session:
            # æ¢å¤æ‰§è¡Œ
            await self._resume_summarize(resume_session)
        else:
            # æ–°çš„æ‰§è¡Œ
            await self._new_summarize(
                input_dir, output_path, compression_level, max_tokens_per_chapter,
                enable_polish, claude_project, claude_model
            )
    
    async def _new_summarize(
        self,
        input_dir: Path, 
        output_path: Path,
        compression_level: int,
        max_tokens_per_chapter: int,
        enable_polish: bool,
        claude_project: Optional[str],
        claude_model: Optional[str]
    ) -> None:
        """æ–°çš„æ€»ç»“ä»»åŠ¡"""
        
        print(f"ğŸš€ å¼€å§‹å¤„ç†MinerUæ•°æ® (V6ç‰ˆæœ¬ - å¸¦æ£€æŸ¥ç‚¹çš„Claude CLI): {input_dir}")
        print(f"ğŸ“Š å‹ç¼©çº§åˆ«: {compression_level}%")
        print(f"ğŸ“„ è¾“å‡ºè·¯å¾„: {output_path}")
        print(f"ğŸ“š æœ€å¤§ç« èŠ‚tokenæ•°: {max_tokens_per_chapter:,}")
        print(f"âœ¨ äºŒæ¬¡æ‰“ç£¨: {'å¯ç”¨' if enable_polish else 'ç¦ç”¨'}")
        print(f"ğŸ¤– Claudeé¡¹ç›®: {claude_project or 'é»˜è®¤'}")
        print(f"ğŸ§  Claudeæ¨¡å‹: {claude_model or 'é»˜è®¤'}")
        
        # 1. è§£æMarkdownæ–‡æ¡£
        print("\næ­¥éª¤1: æŒ‰å¤§ç« èŠ‚è§£æMarkdownæ–‡æ¡£...")
        full_md_path = input_dir / "full.md"
        if not full_md_path.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°full.mdæ–‡ä»¶: {full_md_path}")
        
        parser = ChapterBasedParser(max_tokens_per_chapter=max_tokens_per_chapter)
        chapter_chunks = parser.parse_markdown_file(full_md_path)
        
        print(f"è§£æå®Œæˆ: {len(chapter_chunks)} ä¸ªå¤§ç« èŠ‚")
        parser.print_chapter_info(chapter_chunks)
        
        # 2. åˆ›å»ºæ£€æŸ¥ç‚¹çŠ¶æ€
        session_id = self.checkpoint_manager.create_session_id(input_dir, compression_level)
        state = CheckpointState(
            session_id=session_id,
            input_dir=str(input_dir.absolute()),
            output_path=str(output_path.absolute()),
            compression_level=compression_level,
            max_tokens_per_chapter=max_tokens_per_chapter,
            enable_polish=enable_polish,
            claude_project=claude_project,
            claude_model=claude_model,
            total_chapters=len(chapter_chunks),
            processed_chapters=0,
            current_stage="initial_summary",
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            chapters_file="",
            summaries_file="",
            polished_summaries_file=None,
            completed_chapter_ids=[],
            failed_chapter_ids=[],
            error_log=[]
        )
        
        # ä¿å­˜åˆå§‹æ£€æŸ¥ç‚¹
        self.checkpoint_manager.save_checkpoint(state, chapters=chapter_chunks)
        print(f"ğŸ’¾ å·²åˆ›å»ºä¼šè¯: {session_id}")
        
        # 3. ç”Ÿæˆåˆæ­¥æ€»ç»“
        print(f"\næ­¥éª¤2: ç”Ÿæˆåˆæ­¥æ€»ç»“...")
        summaries = await self._generate_summaries_with_checkpoint(
            chapter_chunks, compression_level, claude_project, claude_model, state
        )
        print(f"åˆæ­¥æ€»ç»“ç”Ÿæˆå®Œæˆ: {len(summaries)} ä¸ªæ€»ç»“å—")
        
        # 4. äºŒæ¬¡æ‰“ç£¨ï¼ˆå¯é€‰ï¼‰
        final_summaries = summaries
        if enable_polish and summaries:
            print(f"\næ­¥éª¤3: äºŒæ¬¡æ‰“ç£¨æ€»ç»“...")
            state.current_stage = "polish"
            state.processed_chapters = 0  # é‡ç½®è¿›åº¦ç”¨äºæ‰“ç£¨é˜¶æ®µ
            state.completed_chapter_ids = []
            self.checkpoint_manager.save_checkpoint(state, summaries=summaries)
            
            polished_summaries = await self._polish_summaries_with_checkpoint(
                summaries, compression_level, claude_project, claude_model, state
            )
            print(f"æ‰“ç£¨å®Œæˆ: {len(polished_summaries)} ä¸ªç²¾åŒ–æ€»ç»“")
            final_summaries = polished_summaries
        
        # 5. å®Œæˆå¤„ç†
        await self._finalize_summary(final_summaries, state, chapter_chunks)
    
    async def _resume_summarize(self, session_id: str) -> None:
        """æ¢å¤æ€»ç»“ä»»åŠ¡"""
        print(f"ğŸ”„ æ¢å¤ä¼šè¯: {session_id}")
        
        # åŠ è½½æ£€æŸ¥ç‚¹
        try:
            state, chapters, summaries, polished_summaries = self.checkpoint_manager.load_checkpoint(session_id)
        except FileNotFoundError:
            print(f"âŒ æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {session_id}")
            return
        
        print(f"ğŸ“Š æ¢å¤çŠ¶æ€: {state.current_stage}")
        print(f"ğŸ“ˆ å·²å®Œæˆ: {len(state.completed_chapter_ids)}/{state.total_chapters}")
        print(f"âŒ å¤±è´¥æ•°é‡: {len(state.failed_chapter_ids)}")
        
        if state.current_stage == "initial_summary":
            # ç»§ç»­ç”Ÿæˆåˆæ­¥æ€»ç»“
            print("\nç»§ç»­ç”Ÿæˆåˆæ­¥æ€»ç»“...")
            summaries = await self._generate_summaries_with_checkpoint(
                chapters, state.compression_level, state.claude_project, state.claude_model, state,
                existing_summaries=summaries
            )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰“ç£¨
            if state.enable_polish and summaries:
                print(f"\nå¼€å§‹äºŒæ¬¡æ‰“ç£¨...")
                state.current_stage = "polish"
                state.processed_chapters = 0
                state.completed_chapter_ids = []
                self.checkpoint_manager.save_checkpoint(state, summaries=summaries)
                
                polished_summaries = await self._polish_summaries_with_checkpoint(
                    summaries, state.compression_level, state.claude_project, state.claude_model, state
                )
                final_summaries = polished_summaries
            else:
                final_summaries = summaries
                
        elif state.current_stage == "polish":
            # ç»§ç»­äºŒæ¬¡æ‰“ç£¨
            print("\nç»§ç»­äºŒæ¬¡æ‰“ç£¨...")
            polished_summaries = await self._polish_summaries_with_checkpoint(
                summaries, state.compression_level, state.claude_project, state.claude_model, state,
                existing_polished=polished_summaries
            )
            final_summaries = polished_summaries
            
        elif state.current_stage == "completed":
            print("âœ… ä¼šè¯å·²å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆè¾“å‡º...")
            final_summaries = polished_summaries if polished_summaries else summaries
        else:
            print(f"âŒ æœªçŸ¥çŠ¶æ€: {state.current_stage}")
            return
        
        # å®Œæˆå¤„ç†
        await self._finalize_summary(final_summaries, state, chapters)
    
    async def _generate_summaries_with_checkpoint(
        self,
        chapter_chunks: List[ChapterChunk],
        compression_level: int,
        claude_project: Optional[str],
        claude_model: Optional[str],
        state: CheckpointState,
        existing_summaries: List[SummaryResult] = None
    ) -> List[SummaryResult]:
        """å¸¦æ£€æŸ¥ç‚¹çš„æ€»ç»“ç”Ÿæˆ"""
        
        if compression_level not in self.config.compression_levels:
            raise ValueError(f"ä¸æ”¯æŒçš„å‹ç¼©çº§åˆ«: {compression_level}")
        
        compression_config = self.config.compression_levels[compression_level]
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        summaries = existing_summaries or []
        completed_ids = set(state.completed_chapter_ids)
        failed_ids = set(state.failed_chapter_ids)
        
        # è¿‡æ»¤éœ€è¦å¤„ç†çš„ç« èŠ‚
        pending_chunks = [chunk for chunk in chapter_chunks 
                         if chunk.id not in completed_ids and chunk.id not in failed_ids]
        
        if not pending_chunks:
            print("âœ… æ‰€æœ‰ç« èŠ‚å·²å¤„ç†å®Œæˆ")
            return summaries
        
        print(f"ğŸ“ éœ€è¦å¤„ç† {len(pending_chunks)} ä¸ªç« èŠ‚ (è·³è¿‡ {len(completed_ids)} ä¸ªå·²å®Œæˆ, {len(failed_ids)} ä¸ªå¤±è´¥)")
        
        # åˆ›å»ºClaude CLIç®¡ç†å™¨
        claude_config = ClaudeCLIConfig(
            project_name=claude_project,
            model=claude_model,
            max_tokens=self.config.llm.max_tokens,
            temperature=self.config.llm.temperature,
            timeout=180
        )
        
        # å¤„ç†ç« èŠ‚
        async with ClaudeCLIManager(
            claude_config, 
            max_concurrent=self.config.processing.max_concurrent
        ) as claude_manager:
            
            with tqdm(total=len(pending_chunks), desc="ç”Ÿæˆæ€»ç»“", initial=len(completed_ids)) as pbar:
                # é€ä¸ªå¤„ç†ä»¥ä¾¿å®æ—¶ä¿å­˜æ£€æŸ¥ç‚¹
                for chunk in pending_chunks:
                    try:
                        # æ„å»ºæç¤ºè¯
                        context_info = f"\n\nç« èŠ‚æ ‡é¢˜: {chunk.chapter_title}"
                        if chunk.sub_sections:
                            context_info += f"\nå­ç« èŠ‚: {', '.join(chunk.sub_sections[:5])}"
                            if len(chunk.sub_sections) > 5:
                                context_info += f" (è¿˜æœ‰{len(chunk.sub_sections)-5}ä¸ªå­ç« èŠ‚)"
                        context_info += f"\nç« èŠ‚è§„æ¨¡: {chunk.token_count:,} tokens"
                        
                        full_prompt = f"""{compression_config.prompt_template}

{context_info}

é‡è¦è¦æ±‚:
1. è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„å¤§ç« èŠ‚ï¼Œè¯·ä¿æŒå†…å®¹çš„è¿è´¯æ€§å’Œé€»è¾‘å®Œæ•´æ€§
2. é‡ç‚¹çªå‡ºç« èŠ‚çš„æ ¸å¿ƒè´¡çŒ®å’Œä¸»è¦è§‚ç‚¹
3. ä¿æŒå­¦æœ¯å†™ä½œçš„ä¸¥è°¨æ€§å’Œä¸“ä¸šæ€§
4. å¯¹äºåŒ…å«å¤šä¸ªå­ç« èŠ‚çš„å†…å®¹ï¼Œè¯·æŒ‰é€»è¾‘é¡ºåºç»„ç»‡æ€»ç»“
5. ä¸“æœ‰æŠ€æœ¯åè¯ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œä¸è¦ç¿»è¯‘ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
   - Graph Neural Networks (GNNs), Graph Foundation Models (GFMs), Transformer
   - Graph Attention Networks (GAT), GraphSAGE, Message Passing, Node Embedding
   - Graph Convolutional Networks (GCN), Self-supervised Learning, Pre-training
   - Fine-tuning, In-context Learning, Few-shot Learning, Zero-shot Learning
   - Knowledge Graph, Heterogeneous Graph, Homogeneous Graph, Graph Isomorphism
   - Graph Pooling, Graph Classification, Node Classification, Link Prediction
   - Graph Generation, Graph Anomaly Detection, Contrastive Learning
   - Multi-modal Learning, Cross-domain Transfer, Domain Adaptation

åŸæ–‡å†…å®¹:
{chunk.content}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½†ä¿æŒä¸Šè¿°è‹±æ–‡æŠ€æœ¯æœ¯è¯­ï¼š"""
                        
                        # è°ƒç”¨Claude CLI
                        summary_text = await claude_manager.single_generate(full_prompt)
                        
                        # åˆ›å»ºç»“æœå¯¹è±¡
                        result = SummaryResult(
                            chunk_id=chunk.id,
                            original_content=chunk.content,
                            summary=summary_text,
                            section_title=chunk.chapter_title,
                            section_level=chunk.chapter_level,
                            token_count=len(summary_text.split()),
                            compression_ratio=self._calculate_compression_ratio(chunk.content, summary_text),
                            metadata={
                                'compression_level': compression_level,
                                'strategy': compression_config.strategy,
                                'original_token_count': chunk.token_count,
                                'sub_sections': chunk.sub_sections,
                                'chapter_parser': 'V6',
                                'claude_cli': True,
                                'claude_project': claude_project,
                                'claude_model': claude_model,
                                'polished': False
                            }
                        )
                        
                        summaries.append(result)
                        state.completed_chapter_ids.append(chunk.id)
                        state.processed_chapters = len(state.completed_chapter_ids)
                        
                        # æ¯å¤„ç†ä¸€ä¸ªç« èŠ‚å°±ä¿å­˜æ£€æŸ¥ç‚¹
                        self.checkpoint_manager.save_checkpoint(state, summaries=summaries)
                        
                        pbar.update(1)
                        
                    except Exception as e:
                        error_info = {
                            'chunk_id': chunk.id,
                            'chapter_title': chunk.chapter_title,
                            'error': str(e),
                            'timestamp': datetime.now().isoformat()
                        }
                        state.failed_chapter_ids.append(chunk.id)
                        state.error_log.append(error_info)
                        
                        print(f"\nâŒ ç« èŠ‚å¤„ç†å¤±è´¥: {chunk.chapter_title}")
                        print(f"   é”™è¯¯: {str(e)}")
                        
                        # ä¿å­˜å¤±è´¥çŠ¶æ€
                        self.checkpoint_manager.save_checkpoint(state, summaries=summaries)
                        
                        # å¦‚æœæ˜¯é™æµé”™è¯¯ï¼Œæç¤ºç”¨æˆ·
                        if "rate limit" in str(e).lower() or "429" in str(e):
                            print(f"â¸ï¸ æ£€æµ‹åˆ°é™æµé”™è¯¯ï¼Œå·²ä¿å­˜æ£€æŸ¥ç‚¹")
                            print(f"   å¯ä»¥ç¨åè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¢å¤: python -m src.main_v6 --resume {state.session_id}")
                            break
                        
                        pbar.update(1)
        
        return summaries
    
    async def _polish_summaries_with_checkpoint(
        self,
        summaries: List[SummaryResult],
        compression_level: int,
        claude_project: Optional[str],
        claude_model: Optional[str],
        state: CheckpointState,
        existing_polished: List[SummaryResult] = None
    ) -> List[SummaryResult]:
        """å¸¦æ£€æŸ¥ç‚¹çš„äºŒæ¬¡æ‰“ç£¨"""
        
        # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
        polished_summaries = existing_polished or []
        completed_ids = set(state.completed_chapter_ids)
        failed_ids = set(state.failed_chapter_ids)
        
        # è¿‡æ»¤éœ€è¦å¤„ç†çš„æ€»ç»“
        pending_summaries = [s for s in summaries 
                           if s.chunk_id not in completed_ids and s.chunk_id not in failed_ids]
        
        if not pending_summaries:
            print("âœ… æ‰€æœ‰æ€»ç»“å·²æ‰“ç£¨å®Œæˆ")
            return polished_summaries
        
        print(f"ğŸ¨ éœ€è¦æ‰“ç£¨ {len(pending_summaries)} ä¸ªæ€»ç»“")
        
        # åˆ›å»ºClaude CLIç®¡ç†å™¨
        claude_config = ClaudeCLIConfig(
            project_name=claude_project,
            model=claude_model,
            max_tokens=self.config.llm.max_tokens,
            temperature=0.2,
            timeout=120
        )
        
        # å¤„ç†æ‰“ç£¨
        async with ClaudeCLIManager(
            claude_config, 
            max_concurrent=max(1, self.config.processing.max_concurrent // 2)
        ) as claude_manager:
            
            with tqdm(total=len(pending_summaries), desc="æ‰“ç£¨æ€»ç»“", initial=len(completed_ids)) as pbar:
                for summary in pending_summaries:
                    try:
                        # æ„å»ºæ‰“ç£¨æç¤ºè¯
                        polish_prompt = f"""ä½ æ˜¯ä¸€åä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¼–è¾‘ï¼Œè¯·å¯¹ä»¥ä¸‹ä¸­æ–‡æ€»ç»“è¿›è¡Œæ‰“ç£¨å’Œä¼˜åŒ–ã€‚

ç« èŠ‚æ ‡é¢˜: {summary.section_title}
å‹ç¼©çº§åˆ«: {compression_level}%

æ‰“ç£¨è¦æ±‚:
1. è¯­è¨€æ¶¦è‰²ï¼šæå‡è¡¨è¾¾çš„æµç•…æ€§å’Œå‡†ç¡®æ€§ï¼Œä½¿ç”¨æ›´åœ°é“çš„ä¸­æ–‡å­¦æœ¯è¡¨è¾¾
2. é€»è¾‘ä¼˜åŒ–ï¼šç¡®ä¿è®ºç‚¹æ¸…æ™°ï¼Œé€»è¾‘é“¾æ¡å®Œæ•´ï¼Œé‡ç‚¹çªå‡º
3. æœ¯è¯­ç»Ÿä¸€ï¼šç¡®ä¿ä¸“æœ‰æŠ€æœ¯åè¯ä½¿ç”¨ä¸€è‡´ï¼Œä¿æŒè‹±æ–‡åŸæ–‡
4. ç»“æ„å®Œå–„ï¼šä¼˜åŒ–æ®µè½ç»“æ„ï¼Œæå‡å¯è¯»æ€§
5. ä¿¡æ¯å¯†åº¦ï¼šåœ¨ä¿æŒ{compression_level}%ä¿¡æ¯é‡çš„åŸºç¡€ä¸Šï¼Œæå‡ä¿¡æ¯çš„ä»·å€¼å¯†åº¦
6. å­¦æœ¯è§„èŒƒï¼šç¬¦åˆä¸­æ–‡å­¦æœ¯å†™ä½œè§„èŒƒï¼Œä¿æŒä¸¥è°¨æ€§

éœ€è¦ä¿æŒè‹±æ–‡çš„æŠ€æœ¯æœ¯è¯­ï¼ˆè¯·å‹¿ç¿»è¯‘ï¼‰:
Graph Neural Networks (GNNs), Graph Foundation Models (GFMs), Transformer, Graph Attention Networks (GAT), GraphSAGE, Message Passing, Node Embedding, Graph Convolutional Networks (GCN), Self-supervised Learning, Pre-training, Fine-tuning, In-context Learning, Few-shot Learning, Zero-shot Learning, Knowledge Graph, Heterogeneous Graph, Homogeneous Graph, Graph Isomorphism, Graph Pooling, Graph Classification, Node Classification, Link Prediction, Graph Generation, Graph Anomaly Detection, Contrastive Learning, Multi-modal Learning, Cross-domain Transfer, Domain Adaptation

åŸå§‹æ€»ç»“:
{summary.summary}

è¯·è¾“å‡ºæ‰“ç£¨åçš„æ€»ç»“ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆç»“æœï¼Œä¸è¦åŒ…å«è¯´æ˜æ€§æ–‡å­—ï¼š"""
                        
                        # è°ƒç”¨æ‰“ç£¨
                        polished_text = await claude_manager.single_generate(polish_prompt)
                        
                        # åˆ›å»ºæ‰“ç£¨åçš„ç»“æœ
                        polished_result = SummaryResult(
                            chunk_id=summary.chunk_id,
                            original_content=summary.original_content,
                            summary=polished_text,
                            section_title=summary.section_title,
                            section_level=summary.section_level,
                            token_count=len(polished_text.split()),
                            compression_ratio=self._calculate_compression_ratio(summary.original_content, polished_text),
                            metadata={
                                **summary.metadata,
                                'polished': True,
                                'original_summary_tokens': summary.token_count,
                                'polish_improvement_ratio': len(polished_text.split()) / summary.token_count if summary.token_count > 0 else 1.0
                            }
                        )
                        
                        polished_summaries.append(polished_result)
                        state.completed_chapter_ids.append(summary.chunk_id)
                        state.processed_chapters = len(state.completed_chapter_ids)
                        
                        # ä¿å­˜æ£€æŸ¥ç‚¹
                        self.checkpoint_manager.save_checkpoint(state, polished_summaries=polished_summaries)
                        
                        pbar.update(1)
                        
                    except Exception as e:
                        error_info = {
                            'chunk_id': summary.chunk_id,
                            'chapter_title': summary.section_title,
                            'error': str(e),
                            'timestamp': datetime.now().isoformat(),
                            'stage': 'polish'
                        }
                        state.failed_chapter_ids.append(summary.chunk_id)
                        state.error_log.append(error_info)
                        
                        print(f"\nâŒ æ‰“ç£¨å¤±è´¥: {summary.section_title}")
                        print(f"   é”™è¯¯: {str(e)}")
                        
                        # ä¿å­˜å¤±è´¥çŠ¶æ€
                        self.checkpoint_manager.save_checkpoint(state, polished_summaries=polished_summaries)
                        
                        # æ£€æŸ¥é™æµ
                        if "rate limit" in str(e).lower() or "429" in str(e):
                            print(f"â¸ï¸ æ£€æµ‹åˆ°é™æµé”™è¯¯ï¼Œå·²ä¿å­˜æ£€æŸ¥ç‚¹")
                            print(f"   å¯ä»¥ç¨åè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¢å¤: python -m src.main_v6 --resume {state.session_id}")
                            break
                        
                        pbar.update(1)
        
        return polished_summaries
    
    async def _finalize_summary(self, summaries: List[SummaryResult], state: CheckpointState, chapters: List[ChapterChunk]) -> None:
        """å®Œæˆæ€»ç»“å¤„ç†"""
        if not summaries:
            print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆçš„æ€»ç»“")
            return
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        overall_stats = SummaryPostProcessor.calculate_overall_stats(summaries)
        print(f"æ€»ä½“ç»Ÿè®¡: {overall_stats}")
        
        # æ ¼å¼åŒ–è¾“å‡º
        print(f"\næ­¥éª¤: æ ¼å¼åŒ–è¾“å‡º...")
        formatter = MarkdownFormatterV2(self.config.output)
        
        # ä»ç¬¬ä¸€ä¸ªå—æå–æ ‡é¢˜
        original_title = self._extract_title(chapters)
        
        formatted_content = formatter.format_summaries(
            summaries=summaries,
            original_title=f"{original_title} (V6 æ£€æŸ¥ç‚¹ç‰ˆ{'+ äºŒæ¬¡æ‰“ç£¨' if state.enable_polish else ''})",
            compression_level=state.compression_level,
            stats=overall_stats
        )
        
        # ä¿å­˜æ–‡ä»¶
        output_path = Path(state.output_path)
        formatter.save_to_file(formatted_content, output_path)
        
        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        state.current_stage = "completed"
        self.checkpoint_manager.save_checkpoint(state, summaries=summaries)
        
        print(f"\nâœ… æ€»ç»“å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"ğŸ“Š åŸå§‹å†…å®¹: {overall_stats.get('total_original_tokens', 0):,} tokens")
        print(f"ğŸ“ æ€»ç»“å†…å®¹: {overall_stats.get('total_summary_tokens', 0):,} tokens") 
        print(f"ğŸ¯ å‹ç¼©æ¯”: {overall_stats.get('overall_compression_ratio', 0):.2%}")
        print(f"ğŸ’¾ ä¼šè¯ID: {state.session_id}")
        
        if state.failed_chapter_ids:
            print(f"âš ï¸ å¤±è´¥ç« èŠ‚æ•°: {len(state.failed_chapter_ids)}")
            print("   å¯ä»¥æŸ¥çœ‹æ£€æŸ¥ç‚¹æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    
    def _calculate_compression_ratio(self, original: str, summary: str) -> float:
        """è®¡ç®—å‹ç¼©æ¯”ä¾‹"""
        original_length = len(original)
        summary_length = len(summary)
        
        if original_length == 0:
            return 0.0
        
        return summary_length / original_length
    
    def _extract_title(self, chunks: List[ChapterChunk]) -> str:
        """ä»æ–‡æ¡£å—ä¸­æå–æ ‡é¢˜"""
        for chunk in chunks:
            if chunk.chapter_level == 1 and not chunk.chapter_title.startswith('Chapter'):
                return chunk.chapter_title
        return "å­¦æœ¯è®ºæ–‡"


async def main():
    """ä¸»å‡½æ•°"""
    # ç®€å•çš„å‘½ä»¤è¡Œå‚æ•°è§£æ
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  æ–°ä»»åŠ¡: python -m src.main_v6 <è¾“å…¥ç›®å½•> <è¾“å‡ºæ–‡ä»¶> [å‹ç¼©çº§åˆ«] [æœ€å¤§ç« èŠ‚tokenæ•°] [æ˜¯å¦æ‰“ç£¨] [Claudeé¡¹ç›®] [Claudeæ¨¡å‹]")
        print("  æ¢å¤ä»»åŠ¡: python -m src.main_v6 --resume <ä¼šè¯ID>")
        print("  åˆ—å‡ºæ£€æŸ¥ç‚¹: python -m src.main_v6 --list")
        print("  æ¸…ç†æ£€æŸ¥ç‚¹: python -m src.main_v6 --clean [ä¿ç•™å¤©æ•°]")
        print("ç¤ºä¾‹:")
        print("  python -m src.main_v6 ./GFM_SURVEY ./summary_v6.md 30 8000 true")
        print("  python -m src.main_v6 --resume abc123def456")
        print("  python -m src.main_v6 --list")
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    try:
        config = load_config()
        print(f"âœ… é…ç½®åŠ è½½å®Œæˆ: ä½¿ç”¨Claude CLI")
    except Exception as e:
        print(f"âŒ é”™è¯¯: é…ç½®åŠ è½½å¤±è´¥: {e}")
        sys.exit(1)
    
    # åˆ›å»ºæ€»ç»“å™¨
    checkpoint_dir = Path(".checkpoints")
    summarizer = MinerUSummarizerV6(config, checkpoint_dir)
    
    # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
    if sys.argv[1] == "--list":
        # åˆ—å‡ºæ£€æŸ¥ç‚¹
        checkpoints = summarizer.checkpoint_manager.list_checkpoints()
        print_checkpoints_table(checkpoints)
        sys.exit(0)
    
    elif sys.argv[1] == "--clean":
        # æ¸…ç†æ£€æŸ¥ç‚¹
        keep_days = int(sys.argv[2]) if len(sys.argv) > 2 else 7
        summarizer.checkpoint_manager.clean_old_checkpoints(keep_days)
        sys.exit(0)
    
    elif sys.argv[1] == "--resume":
        # æ¢å¤ä¼šè¯
        if len(sys.argv) < 3:
            print("âŒ é”™è¯¯: è¯·æä¾›ä¼šè¯ID")
            sys.exit(1)
        
        session_id = sys.argv[2]
        try:
            await summarizer.summarize(
                input_dir=Path("."),  # å ä½ç¬¦ï¼Œä¼šä»æ£€æŸ¥ç‚¹åŠ è½½
                output_path=Path("."),  # å ä½ç¬¦ï¼Œä¼šä»æ£€æŸ¥ç‚¹åŠ è½½
                resume_session=session_id
            )
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ¢å¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
    
    else:
        # æ–°ä»»åŠ¡
        if len(sys.argv) < 3:
            print("âŒ é”™è¯¯: æ–°ä»»åŠ¡éœ€è¦æä¾›è¾“å…¥ç›®å½•å’Œè¾“å‡ºæ–‡ä»¶")
            sys.exit(1)
        
        input_dir = Path(sys.argv[1])
        output_path = Path(sys.argv[2])
        compression_level = int(sys.argv[3]) if len(sys.argv) > 3 else 50
        max_tokens_per_chapter = int(sys.argv[4]) if len(sys.argv) > 4 else 8000
        enable_polish = sys.argv[5].lower() == 'true' if len(sys.argv) > 5 else True
        claude_project = sys.argv[6] if len(sys.argv) > 6 else None
        claude_model = sys.argv[7] if len(sys.argv) > 7 else None
        
        # éªŒè¯è¾“å…¥ç›®å½•
        if not input_dir.exists():
            print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            sys.exit(1)
        
        full_md_path = input_dir / "full.md"
        if not full_md_path.exists():
            print(f"é”™è¯¯: æœªæ‰¾åˆ°full.mdæ–‡ä»¶: {full_md_path}")
            sys.exit(1)
        
        # æµ‹è¯•Claude CLI
        from src.summarizer.claude_cli_client import ClaudeCLIConfig, ClaudeCLIManager
        claude_config = ClaudeCLIConfig(project_name=claude_project, model=claude_model)
        claude_manager = ClaudeCLIManager(claude_config)
        
        if not claude_manager.test_claude_cli():
            print("âŒ é”™è¯¯: Claude CLIä¸å¯ç”¨")
            print("è§£å†³æ–¹æ¡ˆ:")
            print("1. å®‰è£…Claude CLI")
            print("2. ç™»å½•è®¤è¯: claude auth login")
            print("3. æ£€æŸ¥ç‰ˆæœ¬: claude --version")
            sys.exit(1)
        
        # æ‰§è¡Œæ€»ç»“
        try:
            await summarizer.summarize(
                input_dir, 
                output_path, 
                compression_level, 
                max_tokens_per_chapter,
                enable_polish,
                claude_project,
                claude_model
            )
        except Exception as e:
            print(f"âŒ é”™è¯¯: å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())